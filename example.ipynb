{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/jsonformer/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n",
      "Loaded model and tokenizer\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "model_name = \"databricks/dolly-v2-3b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, use_cache=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, use_cache=True)\n",
    "print(\"Loaded model and tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating...\n",
      "top 5 tokens\n",
      "|\n",
      "|: 18.525007247924805\n",
      "|�|: 15.667376518249512\n",
      "|null|: 14.199860572814941\n",
      "| |: 14.177852630615234\n",
      "|\t|: 13.800167083740234\n",
      "decoded_token: |\n",
      "|\n",
      "decoded_token is empty or only spaces or newlines - skipping\n",
      "decoded_token: |�|\n",
      "decoded_token is not null, returning True\n",
      "{\n",
      "  isNull: \u001b[32m0.0\u001b[0m\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from jsonformer.format import highlight_values\n",
    "from jsonformer.main import Jsonformer\n",
    "\n",
    "weather_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"isNull\": {\"type\": [\"number\", \"null\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "builder = Jsonformer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    json_schema=weather_schema,\n",
    "    prompt=\"your response should be null\",\n",
    ")\n",
    "\n",
    "print(\"Generating...\")\n",
    "output = builder()\n",
    "\n",
    "highlight_values(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating...\n",
      "top 5 tokens\n",
      "|\n",
      "|: 17.970674514770508\n",
      "|�|: 15.745203971862793\n",
      "|null|: 15.071812629699707\n",
      "|ull|: 14.74064826965332\n",
      "| |: 14.47098159790039\n",
      "decoded_token: |\n",
      "|\n",
      "decoded_token is empty or only spaces or newlines - skipping\n",
      "decoded_token: |�|\n",
      "decoded_token is not null, returning True\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     11\u001b[0m builder \u001b[39m=\u001b[39m Jsonformer(\n\u001b[1;32m     12\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     13\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[1;32m     14\u001b[0m     json_schema\u001b[39m=\u001b[39mweather_schema,\n\u001b[1;32m     15\u001b[0m     prompt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgenerate null\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGenerating...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m output \u001b[39m=\u001b[39m builder()\n\u001b[1;32m     21\u001b[0m highlight_values(output)\n",
      "File \u001b[0;32m~/jsonformer/jsonformer/main.py:251\u001b[0m, in \u001b[0;36mJsonformer.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    250\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 251\u001b[0m     generated_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_object(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjson_schema[\u001b[39m\"\u001b[39;49m\u001b[39mproperties\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m generated_data\n",
      "File \u001b[0;32m~/jsonformer/jsonformer/main.py:121\u001b[0m, in \u001b[0;36mJsonformer.generate_object\u001b[0;34m(self, properties, obj)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_object\u001b[39m(\n\u001b[1;32m    117\u001b[0m     \u001b[39mself\u001b[39m, properties: Dict[\u001b[39mstr\u001b[39m, Any], obj: Dict[\u001b[39mstr\u001b[39m, Any]\n\u001b[1;32m    118\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    119\u001b[0m     \u001b[39m# self.debug(\"[generate_object] properties\", properties)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[39mfor\u001b[39;00m key, schema \u001b[39min\u001b[39;00m properties\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 121\u001b[0m         obj[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_value(schema, obj, key)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/jsonformer/jsonformer/main.py:191\u001b[0m, in \u001b[0;36mJsonformer.generate_value\u001b[0;34m(self, schema, obj, key)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_boolean()\n\u001b[1;32m    190\u001b[0m \u001b[39melif\u001b[39;00m schema_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_string()\n\u001b[1;32m    192\u001b[0m \u001b[39melif\u001b[39;00m schema_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    193\u001b[0m     new_array \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/jsonformer/jsonformer/main.py:113\u001b[0m, in \u001b[0;36mJsonformer.generate_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39m[generate_string] response\u001b[39m\u001b[39m\"\u001b[39m, response)\n\u001b[1;32m    112\u001b[0m split \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(split) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m split[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from jsonformer.format import highlight_values\n",
    "from jsonformer.main import Jsonformer\n",
    "\n",
    "weather_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"isNull\": {\"type\": [\"string\", \"null\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "builder = Jsonformer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    json_schema=weather_schema,\n",
    "    prompt=\"generate null\",\n",
    ")\n",
    "\n",
    "print(\"Generating...\")\n",
    "output = builder()\n",
    "\n",
    "highlight_values(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
